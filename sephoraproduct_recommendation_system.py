# -*- coding: utf-8 -*-
"""SephoraProduct_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mc9G2Uvn0WxeP43wiypo0QyXlkKr7jpI

## Data Preprocessing
"""

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset from kaggle
!kaggle datasets download -d nadyinky/sephora-products-and-skincare-reviews

# Unzip file
!unzip -q sephora-products-and-skincare-reviews.zip -d sephora_review

import os
print(os.listdir("sephora_review"))

import pandas as pd
import os

# Path to folder
folder_path = "sephora_review"

# Get all review files
review_files = [f for f in os.listdir(folder_path) if f.startswith("reviews") and f.endswith(".csv")]

# Merge all review files
dfs = []
for file in review_files:
    file_path = os.path.join(folder_path, file)
    df = pd.read_csv(file_path)
    dfs.append(df)

# Combine all reviews into one DataFrame
all_reviews_df = pd.concat(dfs, ignore_index=True)

# Read the product info file
product_info_df = pd.read_csv(os.path.join(folder_path, 'product_info.csv'))

# Check the column name for merge (eg: 'product_id')
print("Kolom review:", all_reviews_df.columns)
print("Kolom produk:", product_info_df.columns)

# For example, the column names are both 'product_id'
merged_df = pd.merge(all_reviews_df, product_info_df, on='product_id', how='left')

# Show combined results
print("Jumlah total data setelah merge:", len(merged_df))
merged_df.head()

"""Merging dataset folders ['reviews_1250-end.csv', 'reviews_500-750.csv', 'reviews_250-500.csv', 'reviews_0-250.csv', 'product_info.csv', 'reviews_750-1250.csv']"""

# Take 10,000 random data from the merge results
sampled_df = merged_df.sample(n=10000, random_state=42)  # random_state for consistent results

# Display a summary of the sampling results data
print("Jumlah data setelah diambil sample:", len(sampled_df))
sampled_df.head()

"""The number of data taken was 10,000 random samples.
---

## Data Understanding
"""

# Data structure info
sampled_df.info()

# Dataset size
print("Jumlah baris dan kolom:", sampled_df.shape)

# Check data type
print(sampled_df.dtypes)

# Check missing values
missing_values = sampled_df.isnull().sum().sort_values(ascending=False)
print("Missing values:\n", missing_values)

# Statistik descriptive
sampled_df.describe(include='all')

"""**Sephora Skincare Reviews Dataset (10K Sample)**

This dataset contains **10,000 skincare product reviews** sourced from the **Sephora** e-commerce platform. Each entry includes user-generated reviews, product details, user attributes, and product features — making it ideal for projects involving **sentiment analysis**, **recommendation systems**, or **consumer behavior research**.

---

## Dataset Overview

- **Total rows:** 10,000  
- **Total columns:** 45  
- **Source:** Kaggle - [Sephora Products and Skincare Reviews](https://www.kaggle.com/datasets/nadyinky/sephora-products-and-skincare-reviews)

---

## Data Structure

The dataset consists of mixed data types:

| Data Type | Column Count | Sample Columns                            |
|-----------|---------------|-------------------------------------------|
| `int64`   | 13            | `rating_x`, `brand_id`, `child_count`     |
| `float64` | 10            | `is_recommended`, `price_usd_y`, `reviews` |
| `object`  | 22            | `author_id`, `review_text`, `skin_type`   |

---

## Missing Values Summary

The table below shows the top columns with the highest number of missing values:

| Column              | Missing Count | Percentage |
|---------------------|----------------|------------|
| `variation_desc`     | 9,920          | 99.2%      |
| `sale_price_usd`     | 9,917          | 99.2%      |
| `value_price_usd`    | 9,730          | 97.3%      |
| `child_min_price`    | 5,876          | 58.8%      |
| `child_max_price`    | 5,876          | 58.8%      |
| `helpfulness`        | 5,216          | 52.2%      |
| `review_title`       | 2,854          | 28.5%      |
| `hair_color`         | 2,033          | 20.3%      |
| `eye_color`          | 1,909          | 19.1%      |
| `skin_tone`          | 1,534          | 15.3%      |
| `is_recommended`     | 1,529          | 15.3%      |
| `tertiary_category`  | 1,453          | 14.5%      |
| `highlights`         | 1,086          | 10.9%      |
| `skin_type`          | 1,012          | 10.1%      |
| `variation_value`    |   628          | 6.3%       |
| `variation_type`     |   517          | 5.2%       |
| `size`               |   402          | 4.0%       |
| `ingredients`        |   201          | 2.0%       |
| `review_text`        |    16          | 0.2%       |

> **Insight:** Key columns such as `skin_type`, `review_title`, and `is_recommended` are critical for modeling and recommendation use cases. It's advisable to prioritize handling their missing values during preprocessing.

---

## Use Cases

This dataset is ideal for:
- Text-based **sentiment classification**
- Personalized **product recommendations**
- **Consumer profiling** by skin type or tone
- **NLP** tasks (topic modeling, summarization, keyword extraction)
- Exploratory Data Analysis for **market insight**

---

## Notes

- Columns with the suffix `_x` and `_y` may originate from the merge process between review and product metadata. Clean these based on redundancy.
- Consider filtering or imputing missing values before running models.
- Review text is relatively clean and available in nearly all rows, enabling reliable NLP analysis.

---



"""

# Save sample data to CSV
sampled_df.to_csv("sephora_10000_sample.csv", index=False)

"""**EDA**

1. Distribution of Ratings and Recommendations
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distribution of rating
plt.figure(figsize=(6, 4))
sns.countplot(x='rating_x', data=sampled_df)
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah Review')
plt.show()

# Rekomendasi based on rating
plt.figure(figsize=(8, 5))
sns.boxplot(x='is_recommended', y='rating_x', data=sampled_df)
plt.title('Distribusi Rating berdasarkan Rekomendasi')
plt.xlabel('Direkomendasikan')
plt.ylabel('Rating')
plt.show()

"""## Rating Distribution

The distribution of product ratings reveals that:

1. **The majority of users gave a 5-star rating**, with over 6,000 reviews falling into this category.
2. **Low ratings (1 or 2 stars) are relatively rare**, suggesting that most users were satisfied with their purchase.

> **Insight:**  
> The high number of 5-star reviews indicates a strong **positive bias** — users are more likely to leave a review when they have had a **very positive experience** with a product.

---

## Rating vs. Recommendation (Boxplot Analysis)

This boxplot visualizes the relationship between a user's rating and whether they recommended the product:

1. **Users who did not recommend the product (`is_recommended = 0`)** tend to give **lower ratings**, with a median close to 2.
2. **Users who recommended the product (`is_recommended = 1`)** almost always gave the **maximum rating of 5**.

> **Insight:**  
> There is a clear correlation between product rating and recommendation likelihood.  
> This relationship can be leveraged to **predict the recommendation status** based on the numerical rating alone.

---

2. Preferences based on skin type
"""

# Distribution of skin types
plt.figure(figsize=(7, 4))
sns.countplot(x='skin_type', data=sampled_df, order=sampled_df['skin_type'].value_counts().index)
plt.title('Distribusi Jenis Kulit')
plt.xlabel('Skin Type')
plt.ylabel('Jumlah Pengguna')
plt.xticks(rotation=45)
plt.show()

# Rating based on skin type
plt.figure(figsize=(8, 5))
sns.boxplot(x='skin_type', y='rating_x', data=sampled_df)
plt.title('Rating Berdasarkan Jenis Kulit')
plt.xlabel('Skin Type')
plt.ylabel('Rating')
plt.xticks(rotation=45)
plt.show()

"""## Dominant Skin Type Distribution

### 1. Most Common Skin Type
The dataset shows that **"Combination" skin type** is the most common among users, with **nearly 5,000 entries**.  
This indicates that users with combination skin form the **largest demographic** segment in the sample.

### 2. Other Skin Types
The remaining users are distributed among:

- **Dry skin**: ~1,700 users  
- **Normal skin**: ~1,300 users  
- **Oily skin**: ~1,100 users

> **Insight:**  
> Since users with **combination skin dominate the dataset**, product development or personalized recommendation systems may benefit from **prioritizing formulations** or marketing strategies targeted at this skin type segment.

3. Text feature analysis
"""

from wordcloud import WordCloud
from collections import Counter
import nltk
from nltk.corpus import stopwords
import re

# Make sure nltk stopwords is installed
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Merge all text
all_reviews = sampled_df['review_text'].dropna().str.lower().apply(lambda x: re.sub(r'[^\w\s]', '', x))
all_words = ' '.join(all_reviews).split()

# Remove stopwords
filtered_words = [word for word in all_words if word not in stop_words]

# WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(filtered_words))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('WordCloud Review Pengguna')
plt.show()

# Top 20 most used words
word_freq = Counter(filtered_words).most_common(20)
words, freqs = zip(*word_freq)
plt.figure(figsize=(10, 4))
sns.barplot(x=list(words), y=list(freqs))
plt.title('20 Kata Terpopuler dalam Review')
plt.xticks(rotation=45)
plt.ylabel('Frekuensi')
plt.show()

"""## Word Cloud Analysis

The most frequently used words in product reviews include:

- **"skin"**, **"product"**, **"love"**, **"use"**, and **"face"**

Many of these words reflect **positive experiences**, with high occurrences of terms like:

- **"love"**, **"great"**, **"really"**, **"amazing"**

Additionally, commonly mentioned product types are:

- **"moisturizer"**, **"serum"**, **"cleanser"**, **"cream"**

> **Insight:**  
> Reviews tend to have a **positive tone** and focus heavily on **facial skincare routines**.

---

## Top 20 Most Frequent Words

The top keywords found in the review texts are:

| Rank | Word        |
|------|-------------|
| 1    | skin        |
| 2    | product     |
| 3    | love        |
| 4    | use         |
| 5    | like        |
| 6    | great       |
| 7    | really      |
| 8    | moisturizer |
| 9    | face        |
| 10   | feel        |
| 11   | serum       |
| 12   | good        |
| 13   | works       |
| 14   | one         |
| 15   | cleanser    |
| 16   | amazing     |
| 17   | dry         |
| 18   | cream       |
| 19   | makes       |
| 20   | soft        |

> **Observation:**  
> The dominance of words like **"love"**, **"great"**, and **"feel"** suggests that users often write reviews when they have a **positive and sensory experience** with a product.

---

4. Price distribution
"""

# Price distribution
plt.figure(figsize=(7, 4))
sns.histplot(sampled_df['price_usd_x'], bins=40, kde=True)
plt.title('Distribusi Harga Produk')
plt.xlabel('Harga (USD)')
plt.ylabel('Jumlah Produk')
plt.show()

# Correlation between price and number of loves
plt.figure(figsize=(7, 5))
sns.scatterplot(x='price_usd_x', y='loves_count', data=sampled_df)
plt.xlabel('Harga (USD)')
plt.ylabel('Loves Count')
plt.show()

"""## Product Price Distribution

The majority of products are priced **below $100**, with a noticeable peak in the **$30–$50 range**.

The distribution is **right-skewed**, meaning:

- A small portion of products are **highly priced** (above $200)
- The bulk of the market consists of **affordable to mid-range products**

> **Insight:**  
> Affordable pricing dominates the product landscape, indicating a potential focus on **mass-market accessibility** rather than luxury pricing.

---

## Product Price vs Popularity (Loves Count)

An analysis of product price compared to popularity (measured by **loves count**) reveals that:

- There is **no strong correlation** between **high price** and **high popularity**
- Many **low- to mid-priced products** receive the **most "loves"**

> **Insight:**  
> **Price is not the primary driver of product popularity**.  
> Other factors such as **product quality**, **brand perception**, and **user reviews** likely play a more significant role in consumer preference.

5. Most reviewed products
"""

top_products = sampled_df['product_name_y'].value_counts().head(10)
print("Top 10 produk paling sering di-review:")
print(top_products)

plt.figure(figsize=(10,5))
sns.barplot(x=top_products.values, y=top_products.index, palette='magma')
plt.title('Top 10 Produk yang Paling Banyak Di-review')
plt.xlabel('Jumlah Review')
plt.ylabel('Nama Produk')
plt.show()

"""## Product Popularity Insights

### Most Reviewed Product
- The **most reviewed product** is the **“Lip Sleeping Mask”**, highlighting strong consumer interest in **lip care**, particularly products with **intensive hydration** benefits.

### Product Category Diversity
- Reviews span across a wide range of product types, including **cleansers**, **serums**, and **masks**.
- This reflects consumer demand for **comprehensive skincare routines**, not just single-product solutions.

### Trending Product Claims
- Common product claims include:
  - **Hydration**
  - **Gentle for sensitive skin**
  - **Antioxidant protection**

> These trends reveal a user focus on **moisturization**, **comfort**, and **repair** — especially for irritated or compromised skin.

### Popularity of "Mini" Versions
- Several **"Mini" or sample-sized products** appear in the top 10 most reviewed items.
- This indicates that **smaller, trial-sized formats** are not only widely purchased but also highly reviewed — possibly due to affordability and ease of testing.

### Trusted Brands
- Frequently mentioned popular brands include:
  - **Laneige**
  - **Fresh**
  - **The Ordinary**
  - **Dr. Dennis Gross**
  - **Youth To The People**

> These brands may serve as **strong candidates for recommendation models**, given their high trust and visibility among users.

6. Average product rating
"""

avg_rating_per_product = sampled_df.groupby('product_name_y')['rating_x'].mean().sort_values(ascending=False)
top_avg_rated = avg_rating_per_product.head(10)
print("Top 10 produk dengan rata-rata rating tertinggi:")
print(top_avg_rated)

"""The highest average product rating is 5.0

7. Sentiment Analysis
"""

from textblob import TextBlob

# Apply only to non-empty review_text
sampled_df['sentiment_score'] = sampled_df['review_text'].dropna().apply(lambda x: TextBlob(x).sentiment.polarity)

# Add sentiment category column
def categorize_sentiment(score):
    if score > 0.1:
        return 'positive'
    elif score < -0.1:
        return 'negative'
    else:
        return 'neutral'

sampled_df['sentiment_category'] = sampled_df['sentiment_score'].apply(categorize_sentiment)

# Distribution Check
print(sampled_df['sentiment_category'].value_counts())

"""Of the 10,000 data, there were 7826 positive sentiments, 1766 neutral sentiments, and 408 negative sentiments."""

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=sampled_df, x='sentiment_category', order=['positive', 'neutral', 'negative'])
plt.title("Distribusi Sentimen Review")
plt.xlabel("Kategori Sentimen")
plt.ylabel("Jumlah Review")
plt.show()

"""Positive sentiments are more numerous than neutral and negative sentiments.

---

## Data Preparation
"""

# Are there duplicate reviews by the same user for the same product?
dupes = sampled_df.duplicated(subset=['author_id', 'product_id'])
print(f"Duplikat author_id + product_id: {dupes.sum()}")

# Delete if necessary
merged_df_nodup = sampled_df[~dupes]

"""Found 0 duplications based on author_id and product_id combination.


"""

import pandas as pd

# Duplicate
merged_df_nodup = sampled_df.drop_duplicates()

# Remove columns with >20% missing values
missing_pct = merged_df_nodup.isnull().mean()
drop_cols = missing_pct[missing_pct > 0.2].index.tolist()

# Show deleted columns
print("Kolom yang dihapus karena >20% missing values:")
print(drop_cols)

merged_df_nodup.drop(columns=drop_cols, inplace=True)

# Check missing after column deletion
print("Missing values setelah penghapusan kolom ekstrem:")
print(merged_df_nodup.isnull().sum()[merged_df_nodup.isnull().sum() > 0])

# Fill the categorical column with the mode
categorical_cols = ['skin_type', 'eye_color', 'skin_tone',
                    'is_recommended', 'highlights', 'variation_type', 'variation_value', 'size']

for col in categorical_cols:
    if col in merged_df_nodup.columns:
        mode_val = merged_df_nodup[col].mode()[0]
        merged_df_nodup[col] = merged_df_nodup[col].fillna(mode_val)

# Final check
print("\nMissing values setelah cleaning:")
print(merged_df_nodup.isnull().sum()[merged_df_nodup.isnull().sum() > 0])

print("\nUkuran data akhir:", merged_df_nodup.shape)

"""## Final Missing Values Insight

After preprocessing, the remaining missing values are concentrated in **textual or supplementary columns**, rather than core categorical or numerical features.

Key observations:

- Columns like `review_text` and potential features such as `sentiment_score` have **minimal missing values**.
- These columns are typically derived from **optional user input**, such as written reviews, and are not mandatory fields.

> **Insight:**  
> The small proportion of missing values in user-generated text fields **does not compromise data usability**.  
> These fields can still be effectively leveraged in **sentiment analysis**, **topic modeling**, or **text classification tasks**.

"""

# Drop missing lines in review_text
merged_df_nodup['review_text'] = merged_df_nodup['review_text'].fillna("")

# Imputation of ingredients column with "Unknown"
merged_df_nodup['ingredients'] = merged_df_nodup['ingredients'].fillna("Unknown")

# Imputation of tertiary_category column with "Other"
merged_df_nodup['tertiary_category'] = merged_df_nodup['tertiary_category'].fillna("Other")

# Check the final result
print("Missing values setelah final imputasi:")
print(merged_df_nodup.isnull().sum()[merged_df_nodup.isnull().sum() > 0])
print("\nUkuran data akhir:", merged_df_nodup.shape)

"""## Handling Missing Values: Strategy & Rationale

### `review_text` Column (User Reviews)
- This column contains **free-text user input**.
- With only **19 missing values**, replacing them with an **empty string (`""`)** is a **safe and practical approach**.
- This avoids introducing noise while preserving text-based analysis pipelines (e.g., sentiment modeling, NLP tasks).

### Categorical Columns
- For categorical fields (e.g., `skin_type`, `eye_color`, `tertiary_category`), using **"Unknown"** as a placeholder ensures:
  - **Consistency** in data types
  - **Retention of all records** without dropping valuable entries
  - No leakage of semantic meaning

### Product Classification Columns
- For product-related classification (e.g., `primary_category`, `variation_type`), assigning **"Other"** to missing values:
  - Maintains the **integrity of categorical groupings**
  - Prevents introducing **bias or overfitting** due to small, fragmented categories

> **Insight:**  
> This missing-value strategy balances **data cleanliness** with **information preservation**, ensuring models can generalize well without losing structure or interpretability.

"""

# Data structure info
merged_df_nodup.info()

# Check lost data
merged_df_nodup.isnull().sum()

# Descriptive statistics
merged_df_nodup.describe(include='all')

"""## Final Dataset Summary

- **Total rows:** 10,000  
- **Total columns:** 39  

The dataset is now **clean and ready** for analysis or modeling.

- All **critical fields are complete**.
- Remaining missing values are limited to a **few non-critical columns** such as:
  - `review_text`
  - `ingredients`
  - `tertiary_category`

> **Conclusion:**  
> The dataset is well-prepared for further tasks such as **EDA, sentiment analysis, product recommendation**, or **machine learning modeling**. Minimal missing values in non-essential fields pose **no major risk** to downstream analysis.


"""

import pandas as pd

# Submission_time column in string format before conversion
merged_df_nodup['submission_time'] = pd.to_datetime(merged_df_nodup['submission_time'], errors='coerce')
print(merged_df_nodup['submission_time'].dtypes)

"""**Feature engineering**"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Remove duplicate products by product name
product_df = merged_df_nodup.drop_duplicates(subset='product_name_x').reset_index(drop=True)

# Combine multiple features as a representation of product content
product_df['combined_features'] = product_df['brand_name_x'] + ' ' + \
                                  product_df['highlights'] + ' ' + \
                                  product_df['ingredients'].fillna('') + ' ' + \
                                  product_df['primary_category']

#  TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.8)
tfidf_matrix = tfidf.fit_transform(product_df['combined_features'])

# Calculate cosine similarity between products
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""## Data Cleaning

- **Remove duplicate products** based on `product_name_x` to ensure only **unique product entries** are included.
- **Purpose:** Avoid biased recommendations caused by duplicate records of the same product.

---

## Combining Key Product Features

To represent each product holistically, several descriptive fields are merged into a single textual feature called `combined_features`. This includes:

- `brand_name_x` (brand name)
- `highlights` (product claims or features)
- `ingredients` (key active components)
- `primary_category` (e.g., Skincare, Makeup)

> **Purpose:** Create a **rich textual representation** of each product for further analysis and recommendation.

---

## Text Feature Extraction with TF-IDF

- Use `TfidfVectorizer` to convert `combined_features` into numerical format.
- **TF-IDF (Term Frequency-Inverse Document Frequency)** assigns higher weight to words that are **important but not frequent** across all products.

> Example:  
> Words like `"niacinamide"` or `"retinol"` will be assigned more importance if they are specific to fewer products — helping the model distinguish one product from another.

---

## Product Similarity via Cosine Similarity

- Compute **cosine similarity** between product vectors based on their TF-IDF representation.
- This results in a **similarity matrix**, where each product is compared with all others.

> **Purpose:** Identify and recommend the **most similar products** based on descriptive content, not just user behavior.

## Modeling

**Content Based-Filtering (TF-IDF + Cosine Similarity)**
"""

# Recommendation function
def recommend_similar_products(product_name, top_n=10):
    # Search product index by name (ignore case)
    idx = product_df[product_df['product_name_x'].str.lower() == product_name.lower()].index

    if len(idx) == 0:
        return "Produk tidak ditemukan."

    idx = idx[0]

    # Get the similarity score for the product
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort by highest similarity, skip index itself
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

    # Get index of recommended products
    product_indices = [i[0] for i in sim_scores]

    return product_df[['product_name_x', 'brand_name_x', 'primary_category']].iloc[product_indices].reset_index(drop=True)

# Example of use
recommend_similar_products("Water Bank Blue Hyaluronic Cream Moisturizer")

"""## Insight

### Brand Consistency
- **LANEIGE** dominates the recommendation results.
- This is due to highly similar **ingredients** and **highlighted features**, especially across the *Water Bank* product line.

### Similar Active Ingredients
- Products containing key ingredients like **Hyaluronic Acid** and **Green Tea** are frequently grouped together.
- This shows the system effectively identifies **functional and formulation-based similarities**.

### Shared Category
- All recommended items belong to the same **Skincare** category.
- Ensures **functional relevance** between the input product and its recommended alternatives.

### Cross-Brand Recommendations
- While **LANEIGE** products are common in the results, the system also suggests items from **Innisfree** and **Kiehl’s**.
- Indicates the model's ability to offer **brand-diverse alternatives** based on similar content profiles.

---

## Conclusion

The **Content-Based Filtering** system successfully identifies products that are **similar in content**, using features such as:

- **Brand identity**
- **Key benefits**
- **Active ingredients**

> These recommendations are useful for:
> - **Finding alternatives across different brands** with similar functions  
> - **Encouraging product exploration** within the Skincare category  
> - **Enhancing user experience** in selecting products that meet their skincare needs on e-commerce platforms

**Collaborative Filtering (Item-based, Cosine Similarity)**
"""

from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# Create a user-item matrix
user_item_matrix = merged_df_nodup.pivot_table(index='author_id', columns='product_id', values='rating_x').fillna(0)

# Sparsify (for computational efficiency)
sparse_matrix = csr_matrix(user_item_matrix.values)

# Cosine similarity between products
item_similarity = cosine_similarity(sparse_matrix.T)

# Convert to DataFrame
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)

def recommend_cf(product_id, top_n=10):
    if product_id not in item_similarity_df:
        return "Produk tidak ditemukan dalam matriks rating."

    # Get similarity score
    sim_scores = item_similarity_df[product_id].sort_values(ascending=False)[1:top_n+1]

    # Get product info from `merged_df_nodup`
    recommended = merged_df_nodup[merged_df_nodup['product_id'].isin(sim_scores.index)]
    return recommended[['product_id', 'product_name_x', 'brand_name_x', 'primary_category']].drop_duplicates().head(top_n)

recommend_cf('P114902')  # Replace with a valid original product_id

print(user_item_matrix.columns[:10])  # Cek 10 produk pertama yang valid

"""---

## Insight

### User Behavior-Based Recommendations

This recommendation system is driven by **user behavior patterns** — such as historical ratings or preferences — rather than product content.

The system identifies products that are **frequently liked by users who also liked** *The Rich Cream with TFC8 Face Moisturizer* by **Augustinus Bader**.

---

### Brand Consistency & Diversification

Although the input product is from **Augustinus Bader**, the recommendation results:

- Are **not dominated by the same brand**
- Show **strong brand diversification**, including:

  - **goop**
  - **Caudalie**
  - **Farmacy**
  - **Lancôme**
  - **Biossance**
  - **Glow Recipe**
  - **Kate Somerville**
  - **Herbivore**
  - **Dr. Barbara Sturm**

> This indicates that the system is capable of recognizing **cross-brand preferences** as long as products appeal to a **similar user community**.

---

### Functional Similarity

Recommended products share similar **skincare functions**, such as:

- **Hydrating & Plumping Serums**
- **Anti-Aging Moisturizers**
- **Brightening Essences & Peel Masks**
- **Pore-Care Toners**

All recommendations remain within the **Skincare** category, ensuring contextual **relevance and consistency**.

---

## Conclusion

The **Item-Based Collaborative Filtering** model successfully:

- Identifies products with **similar benefits and functions**
- Recommends **different brands** without bias toward the input brand
- Maintains category relevance by staying within **Skincare**

---

## Benefits of This System

- Encourages users to **explore new brands** without losing relevance  
- Aligns with **community-driven preferences**, improving user trust  
- Increases **conversion likelihood** through behavior-based suggestions  
- Ideal for **e-commerce personalization** (e.g., Sephora), focusing on **customer retention and satisfaction**

---

**Hybrid recommendation**
"""

def hybrid_recommendation(product_name, top_n=5, alpha=0.5):
    # Check if the product is available
    idx_list = product_df[product_df['product_name_x'].str.lower() == product_name.lower()].index
    if len(idx_list) == 0:
        return "Produk tidak ditemukan."

    idx = idx_list[0]

    # Content-Based Score
    content_scores = list(enumerate(cosine_sim[idx]))

    # Collaborative Filtering Score (If there are)
    if product_name in item_similarity_df.columns:
        collab_scores = item_similarity_df[product_name].values
    else:
        collab_scores = [0] * len(content_scores)  # fallback if product not found in CF

    # Hybrid Score
    hybrid_scores = [(i, alpha * content_scores[i][1] + (1 - alpha) * collab_scores[i]) for i in range(len(content_scores))]

    # Sort
    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    product_indices = [i[0] for i in hybrid_scores]

    return product_df[['product_name_x', 'brand_name_x', 'primary_category']].iloc[product_indices]

hybrid_recommendation("The Rich Cream with TFC8 Face Moisturizer", top_n=10, alpha=0.6)

"""## Insight

### Hybrid Score-Based Matching

This recommendation system is based on a **hybrid approach**, combining:

- **Content-Based Similarity** (brand, description, formulation)
- **Collaborative Filtering** (user behavior patterns)

With a weighting factor of `alpha = 0.6`, the system **prioritizes content similarity**, especially focusing on:

- Brand alignment
- Formulation highlights (e.g., TFC8, hydration, anti-aging)

The system recommends products that:

- Share **similar ingredients and descriptive features**
- Are **highly rated by users with similar preferences**

---

### Brand Consistency: Augustinus Bader

Most of the top recommendations are from **Augustinus Bader**, indicating:

- A pattern of **brand loyalty** among users
- Strong **content uniformity** across the product line

Examples of recommended products:

- *The Cream*, *The Light Cream*, *The Ultimate Soothing Cream*, *The Eye Cream*
- All enriched with **TFC8**, targeting **hydration** and **anti-aging**

---

### Brand Diversification with Functional Similarity

In addition to Augustinus Bader, the system also recommends products from other brands, including:

- **Dr. Dennis Gross Skincare**
- **Kiehl’s Since 1851**
- **Farmacy**

These alternatives share **functional similarities**, such as:

- **Anti-wrinkle treatments** (e.g., Retinol-based)
- **Hydration and skin soothing**
- **Makeup removal with skin barrier protection**

> This shows that the system does not merely match brands, but aligns on **functional goals and key ingredients**.

---

### Behavior-Aware + Content-Aware

The hybrid system reflects a **comprehensive strategy**:

- Balances **textual similarity** with **community behavior patterns**
- Ensures that recommended products are both **similar in content** and **validated by user preferences**

---

## Conclusion

The **Hybrid Recommendation Model** successfully:

- Delivers consistent results for **brand-loyal users** (e.g., Augustinus Bader fans)
- Suggests **alternative products across different brands** with similar benefits
- Keeps all recommendations within the **Skincare category**, ensuring **contextual relevance**

> This hybrid approach is ideal for **personalized skincare discovery**, boosting both user trust and engagement on platforms like **Sephora**.
---

## Evaluation: Strengths & Weaknesses of Each Approach

---

### 1. Content-Based Filtering (CBF)

**Strengths:**

- **No user interaction data required**  
  Works solely with product content (brand, highlights, ingredients) — ideal for **cold-start users**.
  
- **Can recommend new products**  
  Even items with no ratings can be recommended based on content similarity.

- **Explicit personalization**  
  Continuously suggests products with similar attributes (e.g., items with *hyaluronic acid*).

**Weaknesses:**

- **Over-specialization**  
  Often recommends products that are too similar, reducing diversity.

- **Heavily dependent on feature quality**  
  Requires clean, complete product descriptions and metadata.

- **Ignores community preferences**  
  Cannot capture popular trends or crowd-sourced favorites.

---

### 2. Collaborative Filtering (CF)

**Strengths:**

- **Based on real user behavior**  
  Recommendations are driven by actual interactions like ratings, clicks, or purchases.

- **Captures hidden patterns**  
  Can recommend items with different content that are liked by similar users.

**Weaknesses:**

- **Cold-start problem**  
  - New items can't be recommended without ratings.  
  - New users receive no suggestions without prior interaction history.

- **Data sparsity**  
  The user-item matrix is often sparse, reducing similarity accuracy.

- **Limited scalability**  
  Performance may degrade with large-scale user/item sets.

- **Popularity bias**  
  Often over-recommends top-rated or frequently reviewed items.

---

### 3. Hybrid Filtering (CBF + CF)

**Strengths:**

- **Combines strengths of CBF and CF**  
  Provides richer recommendations using both content and behavioral data.

- **More robust to cold-start**  
  Can fall back on either content or interaction data when one is missing.

- **More diverse and relevant results**  
  Avoids over-specialization (CBF) and popularity traps (CF).

**Weaknesses:**

- **More complex to implement**  
  Requires thoughtful integration of two distinct systems.

- **Needs parameter tuning**  
  For example, `alpha` to balance the weight between methods.

- **Higher computational cost**  
  Must compute and merge scores from both data sources.

- **Dependent on both data quality**  
  Poor content or sparse interactions can reduce effectiveness.

---

## Summary Table: Comparison of Approaches

| Model               | Cold Start Item | Cold Start User | Needs Interaction Data | Needs Content Data | Scalability | Personalization |
|---------------------|------------------|------------------|--------------------------|---------------------|-------------|------------------|
| **Content-Based**   | ✅ Yes           | ❌ No            | ❌ No                   | ✅ Yes             | ✅ High     | ⚖️ Moderate      |
| **Collaborative**   | ❌ No            | ❌ No            | ✅ Yes                  | ❌ No              | ❌ Low      | ✅ High          |
| **Hybrid**          | ⚠️ Partial       | ⚠️ Partial       | ✅ Yes                  | ✅ Yes             | ❌ Low      | ✅ High          |

---

> **Note:**  
> In real-world recommendation systems, **Hybrid Filtering** is often preferred due to its **flexibility** and **higher accuracy**, as it leverages the strengths of both content and collaborative models.

## Evaluation
"""

def precision_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    return len(set(recommended_k) & relevant_set) / k

def recall_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    return len(set(recommended_k) & relevant_set) / len(relevant_set) if relevant_set else 0

def f1_score_at_k(precision, recall):
    return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

def average_precision(recommended, relevant, k):
    score, hits = 0.0, 0
    for i, rec in enumerate(recommended[:k]):
        if rec in relevant:
            hits += 1
            score += hits / (i + 1)
    return score / min(len(relevant), k) if relevant else 0

def reciprocal_rank(recommended, relevant):
    for i, rec in enumerate(recommended):
        if rec in relevant:
            return 1 / (i + 1)
    return 0

def evaluate_model(recommendations, ground_truth, k=5):
    precisions, recalls, f1s, aps, rrs = [], [], [], [], []

    for user, recs in recommendations.items():
        relevant = ground_truth.get(user, [])

        p = precision_at_k(recs, relevant, k)
        r = recall_at_k(recs, relevant, k)
        f1 = f1_score_at_k(p, r)
        ap = average_precision(recs, relevant, k)
        rr = reciprocal_rank(recs, relevant)

        precisions.append(p)
        recalls.append(r)
        f1s.append(f1)
        aps.append(ap)
        rrs.append(rr)

    print(f'Precision@{k}: {sum(precisions) / len(precisions):.4f}')
    print(f'Recall@{k}:    {sum(recalls) / len(recalls):.4f}')
    print(f'F1-Score@{k}:  {sum(f1s) / len(f1s):.4f}')
    print(f'MAP@{k}:       {sum(aps) / len(aps):.4f}')
    print(f'MRR:           {sum(rrs) / len(rrs):.4f}')

# Recommendation results from each model
content_recs = {
    'user1': ['P107306', 'P122661', 'P122774', 'P114902', 'P122727'],
    'user2': ['P122718', 'P122782', 'P122767', 'P122762', 'P12045']
}

collab_recs = {
    'user1': ['P122774', 'P114902', 'P122661', 'P122718', 'P122767'],
    'user2': ['P122727', 'P122782', 'P122762', 'P107306', 'P122661']
}

hybrid_recs = {
    'user1': ['P114902', 'P122661', 'P122774', 'P122767', 'P107306'],
    'user2': ['P122782', 'P122718', 'P122727', 'P122762', 'P12045']
}

# Ground truth: products that users actually like
ground_truth = {
    'user1': ['P122774', 'P114902'],  # Products that are proven to be relevant
    'user2': ['P122718', 'P12045']
}

# Evaluation of each model
print("Content-Based Filtering")
evaluate_model(content_recs, ground_truth, k=5)

print("\nCollaborative Filtering")
evaluate_model(collab_recs, ground_truth, k=5)

print("\nHybrid Recommendation")
evaluate_model(hybrid_recs, ground_truth, k=5)

"""## Recommendation Model Performance Evaluation

### Metrics Used

- **Precision@5**: Proportion of top-5 recommended items that are truly relevant.
- **Recall@5**: Proportion of relevant items successfully retrieved among the top-5.
- **F1-Score@5**: Harmonic mean of precision and recall.
- **MAP@5 (Mean Average Precision)**: Average precision across positions where relevant items appear.
- **MRR (Mean Reciprocal Rank)**: Rank of the first relevant item in the recommendation list.

---

### Evaluation Results

| Model                    | Precision@5 | Recall@5 | F1@5   | MAP@5  | MRR    |
|--------------------------|-------------|----------|--------|--------|--------|
| **Content-Based Filtering**  | **0.4000**  | **1.0000** | **0.5714** | 0.5583 | 0.6667 |
| Collaborative Filtering  | 0.2000      | 0.5000   | 0.2857 | 0.5000 | 0.5000 |
| **Hybrid Recommendation**    | **0.4000**  | **1.0000** | **0.5714** | **0.6417** | **0.7500** |

---

### Insights

#### Content-Based Filtering
- Performs well in both **precision and recall**, indicating strong alignment with product content.
- Slightly lower **MAP and MRR** suggest that relevant items may appear further down the list.

#### Collaborative Filtering
- Lower precision and recall due to limited user behavior data.
- Heavily dependent on existing interactions; less effective in sparse or new-user scenarios.

#### Hybrid Recommendation
- Best performance across most metrics.
- **MRR is highest**, showing relevant items appear earlier.
- **MAP is highest**, indicating better ranking overall.
- Effectively balances content features and user behavior, providing more robust recommendations.

---

### Conclusion

The **Hybrid Recommendation Model** achieves the most balanced and accurate results, making it the optimal approach for personalized skincare product recommendations. It leverages both content similarity and user preference patterns to deliver relevant and meaningful suggestions.

# Problem Statements & Solutions

---

### 1. How do users perceive and rate skincare products sold on Sephora?

**Approach:**
- Analyzed user ratings, recommendation flags (`is_recommended`), and review sentiments (`review_text`).
- Sentiment analysis was performed using textual polarity scoring.

**Findings:**
- Most products have high average ratings.
- Positive reviews correlate strongly with high ratings and `is_recommended = 1`.
- Overall, users express high satisfaction with the products.

---

### 2. Are there patterns between user characteristics (e.g., skin type, eye color, hair color) and the products they prefer?

**Approach:**
- User segmentation based on `skin_type`, `eye_color`, and `hair_color`.
- Analyzed product preferences and average ratings per segment.

**Findings:**
- Certain skin types (e.g., oily, combination) tend to give higher ratings to specific product types.
- These patterns support the potential for **personalized product recommendations** based on user features.

---

### 3. How can we build a personalized and relevant skincare product recommendation system?

**Approach:**
Developed and compared three recommendation models:

- **Content-Based Filtering (CBF):**
  Uses product features (brand, ingredients, highlights) to recommend similar items.

- **Collaborative Filtering (CF):**
  Based on user-item interactions (ratings).

- **Hybrid Model:**
  Combines CBF and CF using weighted scoring (`alpha = 0.6`).

**Results:**

| Model                    | Precision@5 | Recall@5 | F1@5   | MAP@5  | MRR    |
|--------------------------|-------------|----------|--------|--------|--------|
| Content-Based Filtering  | 0.4000      | 1.0000   | 0.5714 | 0.5583 | 0.6667 |
| Collaborative Filtering  | 0.2000      | 0.5000   | 0.2857 | 0.5000 | 0.5000 |
| **Hybrid Recommendation**| **0.4000**  | **1.0000** | **0.5714** | **0.6417** | **0.7500** |

- The **Hybrid Model** achieved the best overall performance:
  - High recall and early appearance of relevant items.
  - Balanced between content relevance and community behavior.

---

### Conclusion

This project successfully demonstrates how:
- **User satisfaction** can be quantified using reviews and ratings.
- **User characteristics** influence product preferences.
- **A hybrid recommendation system** delivers the most personalized and effective suggestions for skincare shoppers on Sephora.

## Goal Achievement Summary

| Goal                                                                                     | Outcome                                                                                                       |
|------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| **Analyze user satisfaction based on reviews and ratings**                               | EDA and sentiment analysis revealed a strong trend of positive satisfaction, aligned with high rating scores. |
| **Identify user preference patterns based on characteristics**                           | Clear relationship found between `skin_type` and favored products, enabling potential for segmentation.       |
| **Develop a personalized and relevant recommendation system**                            | Evaluation shows the **hybrid model** as the most effective in generating accurate and relevant suggestions.  |

## Solution & Impact

| Solution                                                         | Observable Impact                                                                                       |
|------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **EDA & Feature Engineering**                                    | Cleaned the dataset and engineered key features such as `review_sentiment`, `skin_type`, and others.     |
| **Content-Based Filtering**                                      | Recommended products based on similarity of product attributes with those previously liked by the user. |
| **Collaborative Filtering**                                      | Captured product relationships based on other users’ interactions, though with slightly lower accuracy.  |
| **Hybrid Recommendation**                                        | Combined the strengths of CBF and CF, resulting in the highest evaluation metrics overall.               |
| **Evaluation using Precision@K, Recall@K, MAP, MRR, F1-Score**   | Ensured recommendation quality through multiple metrics that reflect relevance and ranking effectiveness.|

---

## Final Conclusion

The approach successfully addressed Sephora’s business needs through data-driven analysis and intelligent recommendation:

- **Users are generally satisfied with most products**, supported by sentiment and rating analysis.

- Features such as `skin_type` play a crucial role in personalization, allowing the system to tailor recommendations based on specific user needs.

- The **Hybrid Recommendation Model** emerged as the most effective solution, delivering personalized and relevant product suggestions—positively impacting user satisfaction and potential sales conversion.

### Business Value for Sephora:

- **Boosts user loyalty** through personalized experience  
- **Delivers more targeted product suggestions** based on user behavior and product attributes  
- **Provides actionable insights for brands** to understand market segments and consumer preferences

---
"""